{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "60e9d52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import math\n",
    "from sentence_transformers import SentenceTransformer,  LoggingHandler, losses, models, util\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "from sentence_transformers.readers import InputExample\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import os\n",
    "import gzip\n",
    "import csv\n",
    "from sklearn.metrics.pairwise import paired_cosine_distances\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "sts_dataset_path = '../datasets/stsbenchmark.tsv.gz'\n",
    "\n",
    "if not os.path.exists(sts_dataset_path):\n",
    "    util.http_get('https://sbert.net/datasets/stsbenchmark.tsv.gz', sts_dataset_path)\n",
    "\n",
    "train_samples = []\n",
    "dev_samples = []\n",
    "test_samples = []\n",
    "with gzip.open(sts_dataset_path, 'rt', encoding='utf8') as fIn:\n",
    "    reader = csv.DictReader(fIn, delimiter='\\t', quoting=csv.QUOTE_NONE)\n",
    "    for row in reader:\n",
    "        score = float(row['score']) / 5.0  # Normalize score to range 0 ... 1\n",
    "        inp_example = InputExample(texts=[row['sentence1'], row['sentence2']], label=score)\n",
    "\n",
    "        if row['split'] == 'dev':\n",
    "            dev_samples.append(inp_example)\n",
    "        elif row['split'] == 'test':\n",
    "            test_samples.append(inp_example)\n",
    "        else:\n",
    "            train_samples.append(inp_example)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eda8aa2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "BERT = \"bert-base-cased\"\n",
    "ELECTRA = \"google/electra-base-discriminator\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "29ca87e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "words1 = [\"animal\", \"old\",  \"strong\", \"looking\", \"amazing\", \"awful\", \"calm\", \"idea\", \"new\", \"part\", \"right\"] \n",
    "words2 = [\"beast\", \"aged\", \"mighty\", \"facing\", \"incredible\", \"dreadful\", \"quiet\", \"thought\", \"novel\", \"portion\", \"correct\"]\n",
    "\n",
    "words_text_examples = [InputExample(texts=[w1, w2], label=1.0) for w1, w2 in zip(words1, words2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "84d976c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embedding_model = models.Transformer(BERT)\n",
    "pooling_model = models.Pooling(\n",
    "    word_embedding_model.get_word_embedding_dimension(),\n",
    "    pooling_mode_mean_tokens=True,\n",
    "    pooling_mode_cls_token=False,\n",
    "    pooling_mode_max_tokens=False\n",
    ")\n",
    "model_bert = SentenceTransformer(modules=[word_embedding_model, pooling_model])\n",
    "\n",
    "word_embedding_model2 = models.Transformer(ELECTRA)\n",
    "pooling_model2 = models.Pooling(\n",
    "    word_embedding_model.get_word_embedding_dimension(),\n",
    "    pooling_mode_mean_tokens=True,\n",
    "    pooling_mode_cls_token=False,\n",
    "    pooling_mode_max_tokens=False\n",
    ")\n",
    "model_electra = SentenceTransformer(modules=[word_embedding_model2, pooling_model2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9448a86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_enc_1 = model_bert.encode(words1, convert_to_tensor=True)\n",
    "bert_enc_2 = model_bert.encode(words2, convert_to_tensor=True)\n",
    "\n",
    "electra_enc_1 = model_electra.encode(words1, convert_to_tensor=True)\n",
    "electra_enc_2 = model_electra.encode(words2, convert_to_tensor=True)\n",
    "\n",
    "bert_scores = util.cos_sim(bert_enc_1, bert_enc_2)\n",
    "electra_scores = util.cos_sim(electra_enc_1, electra_enc_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "91ab79f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "animal beast \t\t Score: 0.9135\n",
      "old aged \t\t Score: 0.8663\n",
      "strong mighty \t\t Score: 0.8625\n",
      "looking facing \t\t Score: 0.8844\n",
      "amazing incredible \t\t Score: 0.9700\n",
      "awful dreadful \t\t Score: 0.9701\n",
      "calm quiet \t\t Score: 0.9248\n",
      "idea thought \t\t Score: 0.7952\n",
      "new novel \t\t Score: 0.8090\n",
      "part portion \t\t Score: 0.9058\n",
      "right correct \t\t Score: 0.9229\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(bert_scores)):\n",
    "    print(\"{} {} \\t\\t Score: {:.4f}\".format(words1[i], words2[i], bert_scores[i][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b1a83b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "animal beast \t\t Score: 0.7229\n",
      "old aged \t\t Score: 0.5902\n",
      "strong mighty \t\t Score: 0.3471\n",
      "looking facing \t\t Score: 0.5824\n",
      "amazing incredible \t\t Score: 0.9598\n",
      "awful dreadful \t\t Score: 0.8821\n",
      "calm quiet \t\t Score: 0.7524\n",
      "idea thought \t\t Score: 0.6633\n",
      "new novel \t\t Score: 0.5860\n",
      "part portion \t\t Score: 0.7643\n",
      "right correct \t\t Score: 0.8171\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(electra_scores)):\n",
    "    print(\"{} {} \\t\\t Score: {:.4f}\".format(words1[i], words2[i], electra_scores[i][i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
