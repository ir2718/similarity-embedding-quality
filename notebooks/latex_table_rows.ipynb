{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "c7608144",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "4d5e3d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_default = [\n",
    "    (\"bert-base-cased\", [\"mean\"], 13, \n",
    "         [\n",
    "            (\"val_results\", \"test_results\", \"BERT$_{base}$\"),\n",
    "         ]\n",
    "    ),\n",
    "    (\"google-electra-base-discriminator\", [\"mean\"], 13, \n",
    "         [\n",
    "            (\"val_results\",\"test_results\", \"ELECTRA$_{D\\:base}$\"),\n",
    "         ]\n",
    "    ),\n",
    "    (\"google-electra-base-generator\", [\"mean\"], 13, \n",
    "         [\n",
    "            (\"val_results\",\"test_results\", \"ELECTRA$_{G\\:base}$\"),\n",
    "         ]\n",
    "    )\n",
    "]\n",
    "\n",
    "models_wordsim = [\n",
    "    (\"bert-base-cased\", [\"mean\"], 13, \n",
    "         [\n",
    "            (\"val_results_word_similarity\",\"test_results_word_similarity\", \"BERT$_{base}$\"),\n",
    "         ]\n",
    "    ),\n",
    "    (\"google-electra-base-discriminator\", [\"mean\"], 13, \n",
    "         [\n",
    "            (\"val_results_word_similarity\",\"test_results_word_similarity\", \"ELECTRA$_{D\\:base}$\"),\n",
    "         ]\n",
    "    ),\n",
    "    (\"google-electra-base-generator\", [\"mean\"], 13, \n",
    "         [\n",
    "            (\"val_results_word_similarity\",\"test_results_word_similarity\", \"ELECTRA$_{G\\:base}$\"),\n",
    "         ]\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "models_mlm = [\n",
    "    (\"bert-base-cased\", [\"mean\"], 13, \n",
    "         [\n",
    "            (\"val_results__bert-base-cased_model_epoch_9_mlm\", \"test_results__bert-base-cased_model_epoch_9_mlm\", \"BERT$_{base}$\"),\n",
    "         ]\n",
    "    ),\n",
    "    (\"google-electra-base-discriminator\", [\"mean\"], 13, \n",
    "         [\n",
    "            (\"val_results__google-electra-base-discriminator_model_epoch_9_mlm\", \"test_results__google-electra-base-discriminator_model_epoch_9_mlm\", \"ELECTRA$_{D\\:base}$\"),\n",
    "         ]\n",
    "    ),\n",
    "    (\"google-electra-base-generator\", [\"mean\"], 13, \n",
    "         [\n",
    "            (\"val_results__google-electra-base-generator_model_epoch_9_mlm\", \"test_results__google-electra-base-generator_model_epoch_9_mlm\", \"ELECTRA$_{G\\:base}$ \"),\n",
    "         ]\n",
    "    )\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "3be60354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT$_{\\text{base}}$ & 12 & 86.04/85.94 & 82.76/83.01 \\\\\n",
      "ELECTRA$_{\\text{D\\:base}}$ & 3 & 82.14/82.18 & 75.29/76.96 \\\\\n",
      "ELECTRA$_{\\text{G\\:base}}$ & 12 & 86.60/86.36 & 82.54/82.48 \\\\\n",
      "\\midrule\n",
      "BERT$_{\\text{base}}$ & 12 & 85.74/85.74 & 83.92/84.11 \\\\\n",
      "ELECTRA$_{\\text{D\\:base}}$ & 3 & 82.59/82.45 & 76.87/77.40 \\\\\n",
      "ELECTRA$_{\\text{G\\:base}}$ & 12 & 86.47/86.20 & 82.58/82.69 \\\\\n",
      "\\midrule\n",
      "BERT$_{\\text{base}}$ & 12 & 85.89/85.67 & 82.70/82.64 \\\\\n",
      "ELECTRA$_{\\text{D\\:base}}$ & 7 & 84.04/83.72 & 79.93/79.92 \\\\\n",
      "ELECTRA$_{\\text{G\\:base}}$  & 11 & 85.55/85.21 & 80.99/80.91 \\\\\n",
      "\n",
      "0 0 2 2 \n",
      "0 0 2 2 \n",
      "0 0 0 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_rows(models):\n",
    "    for x in models:\n",
    "        m = x[0]\n",
    "        pool = x[1]\n",
    "        c = x[2]\n",
    "        json_names_labels = x[3]\n",
    "        for p in pool:\n",
    "            for (val_name, name, label) in json_names_labels:\n",
    "                spearman, pearson = [], []\n",
    "                std_spearman, std_pearson = [], []\n",
    "                \n",
    "                val_spearman, val_pearson = [], []\n",
    "                for i in range(c):\n",
    "                    res = json.load(open(f\"../output/{m}/{p}/{i}_to_{i+1}/{name}.json\"))\n",
    "                    \n",
    "                    std_1 = np.array(res[\"stdev_cosine_spearman_test\"]) * 100\n",
    "                    mean_1 = res[\"mean_cosine_spearman_test\"] * 100\n",
    "                    std_spearman.append((mean_1-std_1, mean_1+std_1))\n",
    "                    spearman.append(mean_1)\n",
    "\n",
    "                    std_2 = np.array(res[\"stdev_cosine_pearson_test\"]) * 100\n",
    "                    mean_2 = res[\"mean_cosine_pearson_test\"] * 100\n",
    "                    std_pearson.append((mean_2-std_2, mean_2+std_2))\n",
    "                    pearson.append(mean_2)\n",
    "                    \n",
    "                    res_val = json.load(open(f\"../output/{m}/{p}/{i}_to_{i+1}/{val_name}.json\"))\n",
    "                    val_spearman.append(res_val[\"mean_cosine_spearman_val\"] * 100)\n",
    "                    val_pearson.append(res_val[\"mean_cosine_pearson_val\"] * 100)\n",
    "                    \n",
    "                argmax = np.argmax(val_spearman)\n",
    "                print(\"{} & {} & {:.2f}/{:.2f} & {:.2f}/{:.2f} \\\\\\\\\"\n",
    "                    .format(\n",
    "                        \"}}\".join(\"{\\\\text{\".join(label.split(\"{\")).split(\"}\")), \n",
    "                        argmax, \n",
    "                        val_spearman[argmax], \n",
    "                        val_pearson[argmax], \n",
    "                        spearman[argmax], \n",
    "                        pearson[argmax]\n",
    "                    )\n",
    "                )\n",
    "                test_s.append(spearman[argmax])\n",
    "                test_p.append(pearson[argmax])\n",
    "                val_s.append(val_spearman[argmax])\n",
    "                val_p.append(val_pearson[argmax])\n",
    "                \n",
    "best = \"\"\n",
    "                \n",
    "test_s, test_p, val_s, val_p = [], [], [], []\n",
    "for m in zip(models_default):\n",
    "    generate_rows(m)\n",
    "best += \"\\n{} {} {} {} \\n\".format(np.argmax(test_s), np.argmax(test_p), np.argmax(val_s), np.argmax(val_p))\n",
    "print(\"\\\\midrule\")\n",
    "\n",
    "\n",
    "test_s, test_p, val_s, val_p = [], [], [], []\n",
    "for m in zip(models_wordsim):\n",
    "    generate_rows(m)    \n",
    "best += \"{} {} {} {} \\n\".format(np.argmax(test_s), np.argmax(test_p), np.argmax(val_s), np.argmax(val_p))\n",
    "print(\"\\\\midrule\")\n",
    "\n",
    "test_s, test_p, val_s, val_p = [], [], [], []\n",
    "for m in zip(models_mlm):\n",
    "    generate_rows(m)    \n",
    "best += \"{} {} {} {}\\n\".format(np.argmax(test_s), np.argmax(test_p), np.argmax(val_s), np.argmax(val_p))\n",
    "print(best)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "a1906c42",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 6/6 [00:01<00:00,  4.13it/s]\n",
      "100%|█████████████████████████████████████████████| 3/3 [00:01<00:00,  1.52it/s]\n",
      "100%|█████████████████████████████████████████████| 3/3 [00:00<00:00,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " max spearman :  BERT$_{large}$ \n",
      " min params:  BERT$_{tiny}$ \n",
      " max val spearman:  BERT$_{large}$ \n",
      " pearson at max val spearman:  BERT$_{large}$ \n",
      " pearson val at max val spearman:  BERT$_{large}$ \n",
      " \n",
      "\n",
      "BERT$_{\\text{tiny}}$ & 2 & 4.37 & 78.23/77.58 & 69.71/70.57 \\\\\n",
      "BERT$_{\\text{mini}}$ & 4 & 11.10 & 83.10/82.47 & 75.64/76.36 \\\\\n",
      "BERT$_{\\text{small}}$ & 4 & 28.50 & 85.12/84.92 & 79.32/79.68 \\\\\n",
      "BERT$_{\\text{medium}}$ & 8 & 41.11 & 85.72/85.39 & 80.84/81.10 \\\\\n",
      "BERT$_{\\text{base}}$ & 12 & 107.72 & 86.04/85.94 & 82.76/83.01 \\\\\n",
      "BERT$_{\\text{large}}$ & 24 & 332.53 & 88.27/88.25 & 85.58/85.75 \\\\\n",
      "ELECTRA$_{\\text{D\\:small}}$ & 1 & 4.76 & 79.72/79.26 & 68.82/69.63 \\\\\n",
      "ELECTRA$_{\\text{D\\:small\\:last}}$ & 1 & 13.45 & 74.02/73.15 & 66.54/67.00 \\\\\n",
      "ELECTRA$_{\\text{D\\:base}}$ & 3 & 45.10 & 82.14/82.18 & 75.29/76.96 \\\\\n",
      "ELECTRA$_{\\text{D\\:base\\:last}}$ & 3 & 108.89 & 72.32/71.56 & 66.93/67.35 \\\\\n",
      "ELECTRA$_{\\text{D\\:large}}$ & 12 & 182.94 & 84.36/84.40 & 80.54/80.71 \\\\\n",
      "ELECTRA$_{\\text{D\\:large\\:last}}$ & 12 & 334.09 & 35.96/32.66 & 35.53/33.09 \\\\\n",
      "ELECTRA$_{\\text{G\\:small}}$ & 12 & 13.45 & 84.67/84.15 & 81.79/81.16 \\\\\n",
      "ELECTRA$_{\\text{G\\:base}}$ & 12 & 33.31 & 86.60/86.36 & 82.54/82.48 \\\\\n",
      "ELECTRA$_{\\text{G\\:large}}$ & 24 & 50.74 & 87.14/86.72 & 84.61/84.47 \\\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "models = [\n",
    "    [\n",
    "        (\"google-bert_uncased_L-2_H-128_A-2\", 3,\"BERT$_{tiny}$\"),\n",
    "        (\"google-bert_uncased_L-4_H-256_A-4\", 5,\"BERT$_{mini}$\"),\n",
    "        (\"google-bert_uncased_L-4_H-512_A-8\", 5,\"BERT$_{small}$\"),\n",
    "        (\"google-bert_uncased_L-8_H-512_A-8\", 9, \"BERT$_{medium}$\"),\n",
    "        (\"bert-base-cased\", 13, \"BERT$_{base}$\"),\n",
    "        (\"bert-large-cased\", 25, \"BERT$_{large}$\"),\n",
    "    ],\n",
    "    [\n",
    "        (\"google-electra-small-discriminator\", 13, \"ELECTRA$_{D\\:small}$\"),\n",
    "        (\"google-electra-base-discriminator\", 13, \"ELECTRA$_{D\\:base}$\"),\n",
    "        (\"google-electra-large-discriminator\", 25, \"ELECTRA$_{D\\:large}$\"),\n",
    "    ],\n",
    "    [\n",
    "        (\"google-electra-small-generator\", 13, \"ELECTRA$_{G\\:small}$\"),\n",
    "        (\"google-electra-base-generator\", 13, \"ELECTRA$_{G\\:base}$\"),\n",
    "        (\"google-electra-large-generator\", 25, \"ELECTRA$_{G\\:large}$\"),\n",
    "\n",
    "    ]\n",
    "]\n",
    "\n",
    "\n",
    "def count_params(model, i):\n",
    "    x = torch.tensor(0.)\n",
    "    for p in model.embeddings.parameters():\n",
    "        x += torch.prod(torch.tensor(p.shape))\n",
    "    if i > 0:\n",
    "        for p in model.encoder.layer[:i].parameters():\n",
    "            x += torch.prod(torch.tensor(p.shape))\n",
    "    return x/10**6\n",
    "\n",
    "all_ = []\n",
    "all_scores_params_names = []\n",
    "for f in models:\n",
    "   \n",
    "    for m in tqdm(f):\n",
    "        val_means, means = [], []\n",
    "        val_pearson_means, pearson_means = [], []\n",
    "        \n",
    "        name = m[0] if \"google\" not in m[0] else m[0].replace(\"google-\", \"google/\")\n",
    "        model = AutoModel.from_pretrained(name)\n",
    "        for i in range(m[1]):\n",
    "            params = count_params(model, i)\n",
    "            \n",
    "            res = json.load(open(f\"../output/{m[0]}/mean/{i}_to_{i+1}/test_results.json\"))\n",
    "            means.append([res[\"mean_cosine_spearman_test\"]*100, params])\n",
    "            pearson_means.append(res[\"mean_cosine_pearson_test\"]*100)\n",
    "            \n",
    "            res = json.load(open(f\"../output/{m[0]}/mean/{i}_to_{i+1}/val_results.json\"))\n",
    "            val_means.append(res[\"mean_cosine_spearman_val\"] * 100)\n",
    "            val_pearson_means.append(res[\"mean_cosine_pearson_val\"] * 100)\n",
    "\n",
    "        tmp_means = means[:]\n",
    "        argmax = np.argmax(val_means)\n",
    "        s, num_param = np.array(means)[argmax]\n",
    "        p = pearson_means[argmax]\n",
    "        \n",
    "        val_s = val_means[argmax]\n",
    "        val_p = val_pearson_means[argmax]\n",
    "        \n",
    "        all_scores_params_names.append([s, num_param, val_s, p, val_p, argmax, m[2]])\n",
    "        if s != tmp_means[-1][0]:\n",
    "            all_scores_params_names.append(\n",
    "                [\n",
    "                    tmp_means[-1][0], \n",
    "                    tmp_means[-1][1],\n",
    "                    val_means[-1],\n",
    "                    pearson_means[-1],\n",
    "                    val_pearson_means[-1],\n",
    "                    argmax,\n",
    "                    \"\\:last}\".join(m[2].split(\"}\"))]\n",
    "            )\n",
    "        \n",
    "argm_score = np.argmax([p[0] for p in all_scores_params_names])\n",
    "argm_param = np.argmin([p[1] for p in all_scores_params_names])\n",
    "argm_val_s = np.argmax([p[2] for p in all_scores_params_names])\n",
    "argm_p = np.argmax([p[3] for p in all_scores_params_names])\n",
    "argm_val_p = np.argmax([p[4] for p in all_scores_params_names])\n",
    "\n",
    "print(\n",
    "    \" max spearman : \", all_scores_params_names[argm_score][-1], \"\\n\",\n",
    "    \"min params: \", all_scores_params_names[argm_param][-1], \"\\n\",\n",
    "    \"max val spearman: \", all_scores_params_names[argm_val_s][-1],\"\\n\", \n",
    "    \"pearson at max val spearman: \", all_scores_params_names[argm_p][-1],\"\\n\", \n",
    "    \"pearson val at max val spearman: \", all_scores_params_names[argm_val_p][-1],\"\\n\", \n",
    "    \"\\n\"\n",
    ")\n",
    "\n",
    "for p in all_scores_params_names:\n",
    "    rounded = np.round(np.array(p[:-1]).astype(np.float32), decimals=2)\n",
    "    #print(rounded)\n",
    "    print(\n",
    "        \"}}\".join(\"{\\\\text{\".join(p[-1].split(\"{\")).split(\"}\")) + \" & \" +\n",
    "        str(int(rounded[5])) + \" & \" +\n",
    "        \"{:.2f} & \".format(rounded[1]) +\n",
    "        \"{:.2f}/{:.2f} & \".format(rounded[2], rounded[4]) +\n",
    "        \"{:.2f}/{:.2f} \".format(rounded[0], rounded[3]) +\n",
    "        \"\\\\\\\\\"\n",
    "    )\n",
    "\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
